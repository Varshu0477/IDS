# ğŸš€ **Multi-Algorithm Classification Analysis**

## ğŸ“Œ **Overview**
This project implements multiple classification algorithms and evaluates their performance across different train-test split ratios (**80:20, 70:30, and 60:40**). The results are compiled into a **comparative analysis table**.

---

## ğŸ¤– **Algorithms Implemented**
- ğŸ”¹ **AdaBoost**
- ğŸ”¹ **CatBoost**
- ğŸ”¹ **Decision Tree** ğŸŒ³
- ğŸ”¹ **Gradient Boosting** âš¡
- ğŸ”¹ **K-Nearest Neighbors (KNN)** ğŸ”¢
- ğŸ”¹ **Kernel Support Vector Machine (KSVM)**
- ğŸ”¹ **Linear Discriminant Analysis (LDA)**
- ğŸ”¹ **Logistic Regression (LG)**
- ğŸ”¹ **LightGBM (LGBM)** ğŸ”¥
- ğŸ”¹ **Linear Support Vector Machine (LSVM)**
- ğŸ”¹ **Multi-layer Perceptron Classifier (MLPC)** ğŸ§ 
- ğŸ”¹ **NaÃ¯ve Bayes**
- ğŸ”¹ **Quadratic Discriminant Analysis (QDA)**
- ğŸ”¹ **Random Forest** ğŸŒ²ğŸŒ²
- ğŸ”¹ **XGBoost (XGB)** ğŸš€

---

## ğŸ“Š **Dataset**
- ğŸ“‚ The dataset is loaded from **Book1.csv**.
- ğŸ·ï¸ **Categorical features** are encoded using **LabelEncoder**.
- ğŸ”§ **Missing values** are handled using **SimpleImputer** with the **mean strategy**.

---

## ğŸ”„ **Preprocessing Steps**
1ï¸âƒ£ Load and preprocess the dataset (**handle missing values & encode categorical variables**).
2ï¸âƒ£ Split the dataset into **training and test sets** with three different ratios:
   - âœ… **80:20**
   - âœ… **70:30**
   - âœ… **60:40**
3ï¸âƒ£ Standardize features using **StandardScaler**.

---

## ğŸ“ **Model Evaluation Metrics**
For each algorithm and split ratio, the following **performance metrics** are computed:
- âœ… **Accuracy** ğŸ“ˆ
- âœ… **Precision** ğŸ¯
- âœ… **Recall** ğŸ”
- âœ… **F1-Score** ğŸ†
- âœ… **Confusion Matrix** ğŸ“Š

---

## ğŸ“¤ **Output**
- ğŸ“ A **comparative table** summarizing the performance of all models under different train-test split ratios.
- ğŸ“ Results are saved as **`model_comparison_results_5.csv`**.

---

## ğŸ› ï¸ **Dependencies**
Ensure you have the following Python libraries installed before running the script:
```bash
pip install numpy pandas scikit-learn matplotlib xgboost catboost lightgbm
```

---

## â–¶ï¸ **Usage**
Run the script using:
```bash
python IDS.ipynb
```

---

## ğŸ“Œ **Results**
- ğŸ“Š The comparative analysis results are stored in **`model_comparison_results_5.csv`** for further analysis.

---

## ğŸ“œ **License**
This project is **open-source** and available under the **MIT License**. ğŸ“„

---

## ğŸ¤ **Contributions**
ğŸ™Œ Feel free to contribute by **improving the code, adding more models, or refining the analysis**.

ğŸ’¡ Suggestions and pull requests are **welcome**!

---

ğŸš€ **Happy Coding!** ğŸ‰
