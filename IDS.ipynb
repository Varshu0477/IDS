{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.ensemble import (\n",
        "    AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
        ")\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from catboost import CatBoostClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from xgboost import XGBClassifier\n"
      ],
      "metadata": {
        "id": "CbLRNoIk9qyQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "dataset = pd.read_csv('Book1.csv')\n",
        "X = dataset.iloc[:, :-1].values\n",
        "y = dataset.iloc[:, -1].values\n",
        "\n",
        "# Encoding categorical features\n",
        "labelencoder_X = LabelEncoder()\n",
        "X[:, 1] = labelencoder_X.fit_transform(X[:, 1])\n",
        "X[:, 8] = labelencoder_X.fit_transform(X[:, 8])\n",
        "\n",
        "# Encoding the target variable\n",
        "labelencoder_y = LabelEncoder()\n",
        "y = labelencoder_y.fit_transform(y)\n",
        "\n",
        "# Handling missing values\n",
        "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "imputer.fit(X[:, 1:11])\n",
        "X[:, 1:11] = imputer.transform(X[:, 1:11])"
      ],
      "metadata": {
        "id": "NpekcJDB9sxi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List of classifiers\n",
        "classifiers = {\n",
        "    \"AdaBoost\": AdaBoostClassifier(),\n",
        "    \"CatBoost\": CatBoostClassifier(verbose=0),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(),\n",
        "    \"Gradient Boost\": GradientBoostingClassifier(),\n",
        "    \"KNN\": KNeighborsClassifier(),\n",
        "    \"Kernel SVM\": SVC(kernel='rbf', probability=True),\n",
        "    \"LDA\": LinearDiscriminantAnalysis(),\n",
        "    \"Logistic Regression\": LogisticRegression(),\n",
        "    \"LGBM\": LGBMClassifier(verbose=-1),\n",
        "    \"Linear SVM\": SVC(kernel='linear', probability=True),\n",
        "    \"MLP Classifier\": MLPClassifier(max_iter=1000),\n",
        "    \"Naive Bayes\": GaussianNB(),\n",
        "    \"QDA\": QuadraticDiscriminantAnalysis(),\n",
        "    \"Random Forest\": RandomForestClassifier(),\n",
        "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
        "}"
      ],
      "metadata": {
        "id": "6KmhfYo593Pg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run experiments\n",
        "for test_size in splits:\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=0)\n",
        "\n",
        "    # Feature scaling\n",
        "    sc = StandardScaler()\n",
        "    X_train = sc.fit_transform(X_train)\n",
        "    X_test = sc.transform(X_test)\n",
        "\n",
        "    for name, clf in classifiers.items():\n",
        "        clf.fit(X_train, y_train)\n",
        "        y_pred = clf.predict(X_test)\n",
        "\n",
        "        acc = accuracy_score(y_test, y_pred)\n",
        "        pre = precision_score(y_test, y_pred, average='weighted', zero_division=1)\n",
        "        rec = recall_score(y_test, y_pred, average='weighted', zero_division=1)\n",
        "        f1 = f1_score(y_test, y_pred, average='weighted', zero_division=1)\n",
        "\n",
        "        results.append([name, f\"{int((1-test_size)*100)}:{int(test_size*100)}\", acc, pre, rec, f1])"
      ],
      "metadata": {
        "id": "F9LaR3At90IU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Splitting criteria\n",
        "splits = [0.2, 0.3, 0.4]\n",
        "results = []\n"
      ],
      "metadata": {
        "id": "rLfEjh8w9z8G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xONJ-30QHkyQ",
        "outputId": "fd84416c-3005-4561-d483-f5cc349ce3f1"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\n",
            "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "This will raise in a future version.\n",
            "\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Convert results to DataFrame\n",
        "df_results = pd.DataFrame(results, columns=[\"Algorithm\", \"Split\", \"Accuracy\", \"Precision\", \"Recall\", \"F1-score\"])\n",
        "df_results.sort_values(by=[\"Algorithm\", \"Split\"], inplace=True)\n",
        "\n",
        "# Save results to CSV\n",
        "df_results.to_csv(\"model_comparison_results.csv\", index=False)\n",
        "\n",
        "# Display results\n",
        "df_results\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kKWiuyaYIPn_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}